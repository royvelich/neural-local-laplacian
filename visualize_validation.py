#!/usr/bin/env python3
"""
Eigenanalysis Visualization from Validation Data with Ground-Truth Comparison

This script loads the validation data pkl files generated by ValidationMeshUploader
and visualizes:
1. The mesh point cloud
2. Ground-truth Laplacian eigenvectors as scalar fields on the mesh
3. Predicted Laplacian eigenvectors as scalar fields on the mesh
4. Eigenvalue comparison and analysis
5. Eigenvector correlation analysis

Updated to handle both old format (global mesh data) and new format (mesh data per result).
"""

import argparse
import pickle
import zipfile
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

import numpy as np
import torch
import polyscope as ps


@dataclass
class VisualizationConfig:
    """Configuration for eigenanalysis visualization."""
    point_radius: float = 0.005
    show_wireframe: bool = False
    colormap: str = 'coolwarm'
    num_eigenvectors_to_show: int = 8
    enable_eigenvalue_info: bool = True
    enable_correlation_analysis: bool = True


class EigenanalysisVisualizer:
    """Visualizer for Laplacian eigenanalysis results with ground-truth comparison."""

    def __init__(self, config: VisualizationConfig = None):
        self.config = config or VisualizationConfig()
        self.validation_data = None
        self.current_batch_idx = 0

    def setup_polyscope(self):
        """Initialize and configure polyscope."""
        ps.init()
        ps.set_up_dir("z_up")
        ps.look_at(camera_location=[2.0, 2.0, 2.0], target=[0, 0, 0])
        ps.set_ground_plane_mode("none")
        ps.set_background_color((0.05, 0.05, 0.05))  # Dark background

    def load_validation_data(self, pkl_file_path: Path) -> Dict[str, Any]:
        """Load validation data from pickle file."""
        try:
            if pkl_file_path.suffix == '.zip':
                # Extract and load from zip file
                return self._load_from_zip(pkl_file_path)
            else:
                # Load directly from pickle file
                with open(pkl_file_path, 'rb') as f:
                    data = pickle.load(f)
                return data
        except Exception as e:
            raise RuntimeError(f"Failed to load validation data from {pkl_file_path}: {e}")

    def _load_from_zip(self, zip_file_path: Path) -> Dict[str, Any]:
        """Load validation data from zip file (W&B artifact)."""
        temp_dir = Path("temp_extraction")
        temp_dir.mkdir(exist_ok=True)

        try:
            with zipfile.ZipFile(zip_file_path, 'r') as zipf:
                zipf.extractall(temp_dir)

            # Find the validation data pickle file
            pkl_files = list(temp_dir.glob("*_validation_data.pkl"))
            if not pkl_files:
                raise FileNotFoundError("No validation data pickle file found in zip")

            # Load the first validation data file found
            with open(pkl_files[0], 'rb') as f:
                data = pickle.load(f)

            return data

        finally:
            # Cleanup temp directory
            import shutil
            if temp_dir.exists():
                shutil.rmtree(temp_dir)

    def print_data_summary(self, data: Dict[str, Any]):
        """Print summary of loaded validation data."""
        print("\n" + "=" * 60)
        print("VALIDATION DATA SUMMARY")
        print("=" * 60)
        print(f"Epoch: {data['epoch']}")
        print(f"Rank: {data['rank']}")
        print(f"Number of validation batches: {data['num_batches']}")
        print(f"Validation results: {len(data['validation_results'])}")

        if data['validation_results']:
            # Show summary of first result's mesh data
            first_result = data['validation_results'][0]
            if 'mesh_data' in first_result:
                mesh_data = first_result['mesh_data']
                print(f"First result mesh file: {mesh_data.get('mesh_file_path', 'Unknown')}")
                print(f"First result mesh vertices: {mesh_data['vertices'].shape if 'vertices' in mesh_data else 'N/A'}")
                print(f"First result mesh faces: {mesh_data['faces'].shape if 'faces' in mesh_data else 'N/A'}")
                if 'gt_eigenvalues' in mesh_data:
                    print(f"First result GT eigenvalues: {mesh_data['gt_eigenvalues'].shape}")

            # Check if multiple different meshes are used
            mesh_files = set()
            for result in data['validation_results']:
                if 'mesh_data' in result and 'mesh_file_path' in result['mesh_data']:
                    mesh_files.add(result['mesh_data']['mesh_file_path'])

            print(f"Unique mesh files used: {len(mesh_files)}")
            if len(mesh_files) <= 3:  # Show mesh files if not too many
                for i, mesh_file in enumerate(sorted(mesh_files)):
                    print(f"  {i + 1}. {mesh_file}")

            first_result = data['validation_results'][0]
            print(f"\nFirst batch metrics: {list(first_result['metrics'].keys())}")

            if 'eigendata' in first_result and first_result['eigendata']:
                eigendata = first_result['eigendata']
                print(f"Predicted eigenvalues shape: {eigendata['predicted_eigenvalues'].shape if 'predicted_eigenvalues' in eigendata else 'N/A'}")
                print(f"Predicted eigenvectors shape: {eigendata['predicted_eigenvectors'].shape if 'predicted_eigenvectors' in eigendata else 'N/A'}")
                print(f"Matrix size: {eigendata.get('matrix_size', 'N/A')}")

        print("=" * 60)

    def _get_mesh_data_for_batch(self, batch_idx: int) -> Dict[str, torch.Tensor]:
        """
        Get mesh data for a specific batch.

        Args:
            batch_idx: Index of the batch

        Returns:
            Dictionary containing mesh vertices, faces, normals, and ground-truth eigendecomposition
        """
        if batch_idx >= len(self.validation_data['validation_results']):
            raise IndexError(f"Batch index {batch_idx} out of range")

        batch_result = self.validation_data['validation_results'][batch_idx]
        if 'mesh_data' not in batch_result:
            raise ValueError(f"No mesh data found for batch {batch_idx}")

        mesh_data = batch_result['mesh_data']

        return {
            'vertices': mesh_data['vertices'],
            'vertex_normals': mesh_data['vertex_normals'],
            'faces': mesh_data['faces'],
            'gt_eigenvalues': mesh_data['gt_eigenvalues'],
            'gt_eigenvectors': mesh_data['gt_eigenvectors'],
            'mesh_file_path': mesh_data.get('mesh_file_path', 'Unknown'),
            'num_vertices': mesh_data.get('num_vertices', len(mesh_data['vertices'])),
            'num_faces': mesh_data.get('num_faces', len(mesh_data['faces']))
        }

    def print_eigenvalue_analysis(self, gt_eigenvalues: torch.Tensor, pred_eigenvalues: torch.Tensor, batch_idx: int):
        """Print detailed eigenvalue comparison analysis."""
        gt_eigenvals_np = gt_eigenvalues.cpu().numpy()
        pred_eigenvals_np = pred_eigenvalues.cpu().numpy()

        print(f"\n" + "-" * 70)
        print(f"EIGENVALUE COMPARISON ANALYSIS - Batch {batch_idx}")
        print("-" * 70)

        # Ground-truth analysis
        print("GROUND-TRUTH EIGENVALUES:")
        print(f"  Number of eigenvalues: {len(gt_eigenvals_np)}")
        print(f"  First eigenvalue (should be ~0): {gt_eigenvals_np[0]:.2e}")
        if len(gt_eigenvals_np) > 1:
            print(f"  Second eigenvalue (Fiedler): {gt_eigenvals_np[1]:.6f}")
            print(f"  Spectral gap: {gt_eigenvals_np[1] - gt_eigenvals_np[0]:.6f}")
        print(f"  Largest eigenvalue: {gt_eigenvals_np[-1]:.6f}")
        print(f"  Mean eigenvalue: {gt_eigenvals_np.mean():.6f}")

        # Predicted analysis
        print("\nPREDICTED EIGENVALUES:")
        print(f"  Number of eigenvalues: {len(pred_eigenvals_np)}")
        print(f"  First eigenvalue (should be ~0): {pred_eigenvals_np[0]:.2e}")
        if len(pred_eigenvals_np) > 1:
            print(f"  Second eigenvalue (Fiedler): {pred_eigenvals_np[1]:.6f}")
            print(f"  Spectral gap: {pred_eigenvals_np[1] - pred_eigenvals_np[0]:.6f}")
        print(f"  Largest eigenvalue: {pred_eigenvals_np[-1]:.6f}")
        print(f"  Mean eigenvalue: {pred_eigenvals_np.mean():.6f}")

        # Comparison metrics
        min_len = min(len(gt_eigenvals_np), len(pred_eigenvals_np))
        if min_len > 0:
            gt_subset = gt_eigenvals_np[:min_len]
            pred_subset = pred_eigenvals_np[:min_len]

            # Compute errors
            abs_errors = np.abs(pred_subset - gt_subset)
            rel_errors = abs_errors / (np.abs(gt_subset) + 1e-10)

            print(f"\nCOMPARISON METRICS (first {min_len} eigenvalues):")
            print(f"  Mean absolute error: {abs_errors.mean():.6f}")
            print(f"  Max absolute error: {abs_errors.max():.6f}")
            print(f"  Mean relative error: {rel_errors.mean():.6f}")
            print(f"  Max relative error: {rel_errors.max():.6f}")
            print(f"  Correlation coefficient: {np.corrcoef(gt_subset, pred_subset)[0, 1]:.6f}")

        # Check positive semi-definiteness
        print("\nPOSITIVE SEMI-DEFINITENESS CHECK:")
        if gt_eigenvals_np[0] < -1e-10:
            print(f"  ‚ö†Ô∏è  GT: First eigenvalue is significantly negative ({gt_eigenvals_np[0]:.2e})")
        else:
            print("  ‚úÖ GT: Laplacian appears to be positive semi-definite")

        if pred_eigenvals_np[0] < -1e-10:
            print(f"  ‚ö†Ô∏è  PRED: First eigenvalue is significantly negative ({pred_eigenvals_np[0]:.2e})")
        else:
            print("  ‚úÖ PRED: Laplacian appears to be positive semi-definite")

        print("-" * 70)

    def compute_eigenvector_correlations(self, gt_eigenvectors: torch.Tensor, pred_eigenvectors: torch.Tensor) -> np.ndarray:
        """Compute correlation matrix between ground-truth and predicted eigenvectors."""
        gt_eigenvecs_np = gt_eigenvectors.cpu().numpy()
        pred_eigenvecs_np = pred_eigenvectors.cpu().numpy()

        min_cols = min(gt_eigenvecs_np.shape[1], pred_eigenvecs_np.shape[1])
        correlation_matrix = np.zeros((min_cols, min_cols))

        for i in range(min_cols):
            for j in range(min_cols):
                # Compute absolute correlation (eigenvectors can have sign ambiguity)
                corr = np.abs(np.corrcoef(gt_eigenvecs_np[:, i], pred_eigenvecs_np[:, j])[0, 1])
                correlation_matrix[i, j] = corr

        return correlation_matrix

    def print_eigenvector_correlation_analysis(self, correlation_matrix: np.ndarray, batch_idx: int):
        """Print eigenvector correlation analysis."""
        print(f"\n" + "-" * 50)
        print(f"EIGENVECTOR CORRELATION ANALYSIS - Batch {batch_idx}")
        print("-" * 50)

        # Find best matches for each GT eigenvector
        print("Best matches for each GT eigenvector:")
        for i in range(min(8, correlation_matrix.shape[0])):  # Show first 8
            best_match_idx = np.argmax(correlation_matrix[i, :])
            best_correlation = correlation_matrix[i, best_match_idx]
            print(f"  GT Eigenvector {i} ‚Üî Pred Eigenvector {best_match_idx}: {best_correlation:.4f}")

        # Overall statistics
        diagonal_corrs = np.diag(correlation_matrix)
        print(f"\nDiagonal correlations (GT_i vs PRED_i):")
        print(f"  Mean: {diagonal_corrs.mean():.4f}")
        print(f"  Min: {diagonal_corrs.min():.4f}")
        print(f"  Max: {diagonal_corrs.max():.4f}")

        # Check if eigenvectors are well-aligned
        well_aligned = diagonal_corrs > 0.8
        print(f"  Well-aligned (>0.8): {well_aligned.sum()}/{len(diagonal_corrs)}")

        print("-" * 50)

    def visualize_mesh(self, vertices: torch.Tensor, vertex_normals: torch.Tensor, faces: torch.Tensor):
        """Visualize the base mesh point cloud."""
        vertices_np = vertices.cpu().numpy()
        normals_np = vertex_normals.cpu().numpy()
        faces_np = faces.cpu().numpy()

        # Register mesh as surface mesh (with faces)
        if len(faces_np) > 0:
            mesh_surface = ps.register_surface_mesh(
                name="Mesh Surface",
                vertices=vertices_np,
                faces=faces_np,
                enabled=True
            )

            # Add vertex normals
            mesh_surface.add_vector_quantity(
                name="normals",
                values=normals_np * 0.05,  # Scale for visibility
                enabled=False,  # Disabled by default
                color=(0.0, 1.0, 1.0),
                vectortype="ambient"
            )

            print(f"Registered mesh surface with {len(vertices_np)} vertices and {len(faces_np)} faces")
            return mesh_surface
        else:
            # Fallback to point cloud if no faces
            mesh_cloud = ps.register_point_cloud(
                name="Mesh",
                points=vertices_np,
                radius=self.config.point_radius,
                enabled=True
            )

            # Add vertex normals
            mesh_cloud.add_vector_quantity(
                name="normals",
                values=normals_np * 0.05,  # Scale for visibility
                enabled=False,  # Disabled by default
                color=(0.0, 1.0, 1.0),
                vectortype="ambient"
            )

            print(f"Registered mesh point cloud with {len(vertices_np)} vertices")
            return mesh_cloud

    def visualize_eigenvectors(self, mesh_structure, gt_eigenvectors: torch.Tensor, gt_eigenvalues: torch.Tensor,
                               pred_eigenvectors: Optional[torch.Tensor] = None, pred_eigenvalues: Optional[torch.Tensor] = None):
        """Add both ground-truth and predicted eigenvector scalar fields to the mesh."""
        gt_eigenvecs_np = gt_eigenvectors.cpu().numpy()
        gt_eigenvals_np = gt_eigenvalues.cpu().numpy()

        num_to_show = min(self.config.num_eigenvectors_to_show, gt_eigenvecs_np.shape[1])

        print(f"Adding {num_to_show} ground-truth eigenvector scalar fields...")

        # Add ground-truth eigenvectors
        for i in range(num_to_show):
            eigenvector = gt_eigenvecs_np[:, i]
            eigenvalue = gt_eigenvals_np[i]

            # Create descriptive name for GT with zero-padded numbering
            if i == 0:
                name = f"GT Eigenvector {i:02d} (Œª={eigenvalue:.2e}, constant)"
            elif i == 1:
                name = f"GT Eigenvector {i:02d} (Œª={eigenvalue:.6f}, Fiedler)"
            else:
                name = f"GT Eigenvector {i:02d} (Œª={eigenvalue:.6f})"

            # Add as scalar quantity
            mesh_structure.add_scalar_quantity(
                name=name,
                values=eigenvector,
                enabled=(i == 1),  # Enable GT Fiedler vector by default
                cmap=self.config.colormap
            )

            print(f"  {name}: range=[{eigenvector.min():.4f}, {eigenvector.max():.4f}]")

        # Add predicted eigenvectors if available
        if pred_eigenvectors is not None and pred_eigenvalues is not None:
            pred_eigenvecs_np = pred_eigenvectors.cpu().numpy()
            pred_eigenvals_np = pred_eigenvalues.cpu().numpy()

            num_pred_to_show = min(num_to_show, pred_eigenvecs_np.shape[1])

            print(f"Adding {num_pred_to_show} predicted eigenvector scalar fields...")

            for i in range(num_pred_to_show):
                eigenvector = pred_eigenvecs_np[:, i]
                eigenvalue = pred_eigenvals_np[i]

                # Create descriptive name for predictions with zero-padded numbering
                if i == 0:
                    name = f"PRED Eigenvector {i:02d} (Œª={eigenvalue:.2e}, constant)"
                elif i == 1:
                    name = f"PRED Eigenvector {i:02d} (Œª={eigenvalue:.6f}, Fiedler)"
                else:
                    name = f"PRED Eigenvector {i:02d} (Œª={eigenvalue:.6f})"

                # Add as scalar quantity
                mesh_structure.add_scalar_quantity(
                    name=name,
                    values=eigenvector,
                    enabled=False,  # Disabled by default
                    cmap=self.config.colormap  # Same colormap as GT
                )

                print(f"  {name}: range=[{eigenvector.min():.4f}, {eigenvector.max():.4f}]")

    def visualize_batch(self, batch_idx: int = 0):
        """Visualize eigenanalysis results for a specific batch with ground-truth comparison."""
        if not self.validation_data:
            print("No validation data loaded!")
            return

        if batch_idx >= len(self.validation_data['validation_results']):
            print(f"Batch index {batch_idx} out of range (max: {len(self.validation_data['validation_results']) - 1})")
            return

        self.current_batch_idx = batch_idx
        batch_result = self.validation_data['validation_results'][batch_idx]

        print(f"\nVisualizing batch {batch_idx} with ground-truth comparison...")

        # Clear previous visualization
        ps.remove_all_structures()

        # Get mesh data for this specific batch
        try:
            mesh_data = self._get_mesh_data_for_batch(batch_idx)
        except Exception as e:
            print(f"Error getting mesh data for batch {batch_idx}: {e}")
            return

        vertices = mesh_data['vertices']
        vertex_normals = mesh_data['vertex_normals']
        faces = mesh_data['faces']
        gt_eigenvalues = mesh_data['gt_eigenvalues']
        gt_eigenvectors = mesh_data['gt_eigenvectors']

        print(f"Mesh file: {mesh_data['mesh_file_path']}")
        print(f"Mesh has {mesh_data['num_vertices']} vertices and {mesh_data['num_faces']} faces")

        # Visualize base mesh
        mesh_structure = self.visualize_mesh(vertices, vertex_normals, faces)

        # Get predicted eigenanalysis results if available
        pred_eigenvalues = None
        pred_eigenvectors = None

        if 'eigendata' in batch_result and batch_result['eigendata']:
            eigendata = batch_result['eigendata']
            if 'predicted_eigenvalues' in eigendata and 'predicted_eigenvectors' in eigendata:
                pred_eigenvalues = eigendata['predicted_eigenvalues']
                pred_eigenvectors = eigendata['predicted_eigenvectors']

        # Print eigenvalue analysis
        if self.config.enable_eigenvalue_info and pred_eigenvalues is not None:
            self.print_eigenvalue_analysis(gt_eigenvalues, pred_eigenvalues, batch_idx)

        # Print eigenvector correlation analysis
        if self.config.enable_correlation_analysis and pred_eigenvectors is not None:
            correlation_matrix = self.compute_eigenvector_correlations(gt_eigenvectors, pred_eigenvectors)
            self.print_eigenvector_correlation_analysis(correlation_matrix, batch_idx)

        # Visualize eigenvectors (both GT and predicted)
        self.visualize_eigenvectors(
            mesh_structure,
            gt_eigenvectors,
            gt_eigenvalues,
            pred_eigenvectors,
            pred_eigenvalues
        )

        # Print batch metrics
        metrics = batch_result['metrics']
        print(f"\nBatch {batch_idx} metrics:")
        for key, value in metrics.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.item():.6f}")
            else:
                print(f"  {key}: {value}")

    def run_automatic_iteration(self, pkl_file_path: Path):
        """Run visualization that automatically iterates through all validation results."""
        # Load validation data
        print(f"Loading validation data from: {pkl_file_path}")
        self.validation_data = self.load_validation_data(pkl_file_path)

        # Print summary
        self.print_data_summary(self.validation_data)

        if not self.validation_data['validation_results']:
            print("No validation results found in data!")
            return

        num_batches = len(self.validation_data['validation_results'])
        print(f"\n{'=' * 60}")
        print("AUTOMATIC ITERATION MODE")
        print("=" * 60)
        print(f"Will iterate through {num_batches} validation results")
        print("Close each window to proceed to the next result")
        print("Features:")
        print("  - Ground-truth eigenvectors: GT Eigenvector X")
        print("  - Predicted eigenvectors: PRED Eigenvector X")
        print("  - Both use the same colormap for easy comparison")
        print("  - Eigenvalue comparison and correlation analysis in terminal")
        print("  - Each result shows its own mesh data")
        print("=" * 60)

        # Iterate through all validation results
        for batch_idx in range(num_batches):
            print(f"\nüîç Showing validation result {batch_idx + 1}/{num_batches}")

            # Setup polyscope for this iteration
            self.setup_polyscope()

            # Visualize this batch
            self.visualize_batch(batch_idx)

            print(f"Window opened for result {batch_idx + 1}. Close window to continue to next result.")

            # Show visualization (blocks until window is closed)
            ps.show()

            # Clear structures for next iteration
            ps.remove_all_structures()

        print(f"\n‚úÖ Completed visualization of all {num_batches} validation results!")


def main():
    """Main function with command line interface."""
    parser = argparse.ArgumentParser(description="Visualize Laplacian eigenanalysis with ground-truth comparison")
    parser.add_argument("pkl_file", type=str, help="Path to validation data pickle file or zip")
    parser.add_argument("--point_radius", type=float, default=0.005, help="Point radius for mesh visualization")
    parser.add_argument("--num_eigenvectors", type=int, default=40, help="Number of eigenvectors to show")
    parser.add_argument("--colormap", type=str, default='coolwarm', help="Colormap for GT eigenvectors")
    parser.add_argument("--disable_correlation", action='store_true', help="Disable eigenvector correlation analysis")

    args = parser.parse_args()

    # Validate file path
    pkl_file_path = Path(args.pkl_file)
    if not pkl_file_path.exists():
        raise FileNotFoundError(f"File not found: {pkl_file_path}")

    # Create visualization config
    vis_config = VisualizationConfig(
        point_radius=args.point_radius,
        num_eigenvectors_to_show=args.num_eigenvectors,
        colormap=args.colormap,
        enable_correlation_analysis=not args.disable_correlation
    )

    # Create visualizer and run automatic iteration
    visualizer = EigenanalysisVisualizer(config=vis_config)
    visualizer.run_automatic_iteration(pkl_file_path)


if __name__ == "__main__":
    main()